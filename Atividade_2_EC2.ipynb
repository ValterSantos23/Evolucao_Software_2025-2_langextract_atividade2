{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValterSantos23/Evolucao_Software_2025-2_langextract_atividade2/blob/main/Atividade_2_EC2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U transformers bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "78gDbSdDKNwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d33adae-0a7f-42a1-9a98-0423704265ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!git clone https://github.com/google/langextract.git || true\n",
        "\n",
        "# Extrair metadados técnicos\n",
        "branches = !cd langextract && git branch -a\n",
        "tags = !cd langextract && git tag -l | tail -n 12\n",
        "history = !cd langextract && git log --merges --oneline -n 15\n",
        "\n",
        "# Consolidar em uma variável de contexto\n",
        "resumo_projeto = f\"\"\"\n",
        "Dados extraídos do repositório 'langextract':\n",
        "1. Branches detectadas: {branches}\n",
        "2. Últimas Tags (Releases): {tags}\n",
        "3. Padrão de Merges (Workflow): {history}\n",
        "\"\"\"\n",
        "\n",
        "print(\"Dados do projeto extraídos com sucesso!\")\n",
        "print(resumo_projeto)"
      ],
      "metadata": {
        "id": "3PTyuEKjKNwL",
        "outputId": "618ea396-1b0c-4677-ab5c-af53f27d1b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'langextract' already exists and is not an empty directory.\n",
            "Dados do projeto extraídos com sucesso!\n",
            "\n",
            "Dados extraídos do repositório 'langextract':\n",
            "1. Branches detectadas: ['* \\x1b[32mmain\\x1b[m', '  \\x1b[31mremotes/origin/Dawn-Of-Justice/main\\x1b[m', '  \\x1b[31mremotes/origin/HEAD\\x1b[m -> origin/main', '  \\x1b[31mremotes/origin/YeonwooSung/main\\x1b[m', '  \\x1b[31mremotes/origin/add-infrastructure-protection-check\\x1b[m', '  \\x1b[31mremotes/origin/add-pr-validation-workflows\\x1b[m', '  \\x1b[31mremotes/origin/aniketchopade/main\\x1b[m', '  \\x1b[31mremotes/origin/azure-openai\\x1b[m', '  \\x1b[31mremotes/origin/chore/bump-version-1.1.1\\x1b[m', '  \\x1b[31mremotes/origin/community-provider-registry\\x1b[m', '  \\x1b[31mremotes/origin/feat-tokenization-benchmark\\x1b[m', '  \\x1b[31mremotes/origin/feat/add-zenodo-doi-support\\x1b[m', '  \\x1b[31mremotes/origin/feat/debug-logging\\x1b[m', '  \\x1b[31mremotes/origin/feat/ollama-quickstart\\x1b[m', '  \\x1b[31mremotes/origin/feature/google-service-accounts\\x1b[m', '  \\x1b[31mremotes/origin/feature/live-api-tests\\x1b[m', '  \\x1b[31mremotes/origin/feature/multi-language-tokenizer\\x1b[m', '  \\x1b[31mremotes/origin/feature/prompt-validation\\x1b[m', '  \\x1b[31mremotes/origin/feature/refactor-architecture\\x1b[m', '  \\x1b[31mremotes/origin/feature/schema-constraints-for-openai\\x1b[m', '  \\x1b[31mremotes/origin/feature/utf8-visualization-support\\x1b[m', '  \\x1b[31mremotes/origin/fix-duplicate-exceptions\\x1b[m', '  \\x1b[31mremotes/origin/fix-linting-config\\x1b[m', '  \\x1b[31mremotes/origin/fix-ollama-num-threads-typo\\x1b[m', '  \\x1b[31mremotes/origin/fix-progress-bar-visibility\\x1b[m', '  \\x1b[31mremotes/origin/fix-pylint-provider-issues\\x1b[m', '  \\x1b[31mremotes/origin/fix-save-annotated-documents-mkdir\\x1b[m', '  \\x1b[31mremotes/origin/fix-visualize-return-type\\x1b[m', '  \\x1b[31mremotes/origin/fix/annotation-generator-align\\x1b[m', '  \\x1b[31mremotes/origin/fix/autoformat-and-deps\\x1b[m', '  \\x1b[31mremotes/origin/fix/google-style-imports\\x1b[m', '  \\x1b[31mremotes/origin/fix/gpt5-model-support\\x1b[m', '  \\x1b[31mremotes/origin/fix/issue-285\\x1b[m', '  \\x1b[31mremotes/origin/fix/kwargs-passthrough\\x1b[m', '  \\x1b[31mremotes/origin/fix/ollama-data-attribute-error\\x1b[m', '  \\x1b[31mremotes/origin/fix/ollama-hf-model-ids\\x1b[m', '  \\x1b[31mremotes/origin/fix/ollama-kwargs-passthrough\\x1b[m', '  \\x1b[31mremotes/origin/fix/test-import-order\\x1b[m', '  \\x1b[31mremotes/origin/investigate-url-bug-177\\x1b[m', '  \\x1b[31mremotes/origin/jkitaok/main\\x1b[m', '  \\x1b[31mremotes/origin/llamacpp-provider\\x1b[m', '  \\x1b[31mremotes/origin/main\\x1b[m', '  \\x1b[31mremotes/origin/ollama-timeout\\x1b[m', '  \\x1b[31mremotes/origin/ollama-timeout-fix\\x1b[m', '  \\x1b[31mremotes/origin/openai_base_url\\x1b[m', '  \\x1b[31mremotes/origin/patch-1\\x1b[m', '  \\x1b[31mremotes/origin/praneeth999/main\\x1b[m', '  \\x1b[31mremotes/origin/refactor/module-compatibility\\x1b[m', '  \\x1b[31mremotes/origin/restore-lost-prs\\x1b[m', '  \\x1b[31mremotes/origin/test-live-api-pr-51\\x1b[m', '  \\x1b[31mremotes/origin/unicode\\x1b[m']\n",
            "2. Últimas Tags (Releases): ['v1.0.0', 'v1.0.1', 'v1.0.2', 'v1.0.3', 'v1.0.4', 'v1.0.5', 'v1.0.6', 'v1.0.7', 'v1.0.8', 'v1.0.9', 'v1.1.0', 'v1.1.1']\n",
            "3. Padrão de Merges (Workflow): ['\\x1b[33m599a776\\x1b[m Merge pull request #31 from google/feature/add-oai-inference', '\\x1b[33mac1fa8b\\x1b[m Merge pull request #29 from google/fix-save-annotated-documents-mkdir', '\\x1b[33m348e0d9\\x1b[m Merge pull request #28 from google/fix/remove-breaking-dep-langfun', '\\x1b[33meb315b4\\x1b[m Merge pull request #26 from google/feat/exception-hierarchy', '\\x1b[33m1b30bb0\\x1b[m Merge pull request #24 from google/feat/code-formatting-pipeline', '\\x1b[33m557389d\\x1b[m Merge pull request #17 from google/fix/output-dir-consistency', '\\x1b[33m00acd38\\x1b[m Merge pull request #15 from kleeena/docs/update-medication_examples.md', '\\x1b[33m09c3208\\x1b[m Merge pull request #11 from google/fix/libmagic-dependency-issue']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes accelerate\n",
        "!pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNioqa8Rkwm_",
        "outputId": "99584060-213d-4f91-fc1c-ddee89d73e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
        "import torch\n",
        "\n",
        "model_id = \"NousResearch/Hermes-2-Pro-Mistral-7B\"\n",
        "#model_id = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "\n",
        "# Configuração para rodar na GPU gratuita do Colab\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "print(f\"Modelo {model_id} carregado!\")"
      ],
      "metadata": {
        "id": "WcqkRFbLKNwL",
        "outputId": "332936df-7c12-4c7f-9d77-d73f9225535d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3163751437.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4879\u001b[0m                 )\n\u001b[1;32m   4880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4881\u001b[0;31m         hf_quantizer, config, dtype, device_map = get_hf_quantizer(\n\u001b[0m\u001b[1;32m   4882\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4883\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py\u001b[0m in \u001b[0;36mget_hf_quantizer\u001b[0;34m(config, quantization_config, dtype, from_tf, from_flax, device_map, weights_only, user_agent)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             )\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_library_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;34m\"Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             )\n",
            "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Extrair tags com datas\n",
        "tags_com_datas = !cd langextract && git for-each-ref \\\n",
        "  --sort=creatordate \\\n",
        "  --format='%(refname:short)|%(creatordate:iso8601)' refs/tags\n",
        "\n",
        "# Converter para lista estruturada\n",
        "tags_datas = []\n",
        "for linha in tags_com_datas:\n",
        "    tag, data = linha.split(\"|\")\n",
        "    tags_datas.append((tag.strip(), data.strip()))\n",
        "\n",
        "tags_datas[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BtHK3KZWFDH",
        "outputId": "5ed176bd-a12d-41d7-e171-539bf8d6885b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('v1.0.0', '2025-07-22 17:57:40 -0400'),\n",
              " ('v1.0.1', '2025-08-02 02:39:45 -0400'),\n",
              " ('v1.0.2', '2025-08-03 09:44:18 -0400'),\n",
              " ('v1.0.3', '2025-08-03 13:23:47 -0400'),\n",
              " ('v1.0.4', '2025-08-05 08:28:44 -0400'),\n",
              " ('v1.0.5', '2025-08-07 21:31:30 -0400'),\n",
              " ('v1.0.6', '2025-08-13 06:13:57 -0400'),\n",
              " ('v1.0.7', '2025-08-14 07:35:16 -0400'),\n",
              " ('v1.0.8', '2025-08-15 03:17:41 -0400'),\n",
              " ('v1.0.9', '2025-08-31 15:41:25 -0400')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from statistics import mean, stdev\n",
        "\n",
        "# Converter datas\n",
        "datas = [datetime.fromisoformat(d) for _, d in tags_datas]\n",
        "\n",
        "# Intervalos em horas (mais preciso para releases no mesmo dia)\n",
        "intervalos_horas = [\n",
        "    (datas[i] - datas[i-1]).total_seconds() / 3600\n",
        "    for i in range(1, len(datas))\n",
        "]\n",
        "\n",
        "resumo_intervalos = {\n",
        "    \"quantidade_releases\": len(datas),\n",
        "    \"intervalo_medio_horas\": round(mean(intervalos_horas), 2),\n",
        "    \"intervalo_min_horas\": round(min(intervalos_horas), 2),\n",
        "    \"intervalo_max_horas\": round(max(intervalos_horas), 2),\n",
        "    \"desvio_padrao_horas\": round(stdev(intervalos_horas), 2) if len(intervalos_horas) > 1 else 0\n",
        "}\n",
        "\n",
        "resumo_intervalos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkyyN15gWZ9Q",
        "outputId": "68332844-c3ec-4cce-e7c5-8518576334b9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'quantidade_releases': 12,\n",
              " 'intervalo_medio_horas': 277.71,\n",
              " 'intervalo_min_horas': 3.66,\n",
              " 'intervalo_max_horas': 1802.65,\n",
              " 'desvio_padrao_horas': 522.59}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def limpar_ansi(texto):\n",
        "    \"\"\"Remove códigos de cores e formatação do terminal (ANSI)\"\"\"\n",
        "    return re.sub(r'\\x1b\\[[0-9;]*m', '', str(texto))\n",
        "\n",
        "# 1. Limpando os dados do repositório para a IA e para a exibição\n",
        "branches_limpas = [limpar_ansi(b) for b in branches[:15]] # Limita a 15 branches\n",
        "tags_limpas = [limpar_ansi(t) for t in tags]\n",
        "history_limpo = [limpar_ansi(h) for h in history]\n",
        "\n",
        "# 2. Criando o contexto limpo\n",
        "contexto_limpo = f\"\"\"\n",
        "Repositório: google/langextract\n",
        "\n",
        "Tags com datas (ordem cronológica):\n",
        "{tags_datas}\n",
        "\n",
        "Estatísticas descritivas dos intervalos entre releases:\n",
        "- Total de releases: {resumo_intervalos['quantidade_releases']}\n",
        "- Intervalo médio: {resumo_intervalos['intervalo_medio_horas']} horas\n",
        "- Intervalo mínimo: {resumo_intervalos['intervalo_min_horas']} horas\n",
        "- Intervalo máximo: {resumo_intervalos['intervalo_max_horas']} horas\n",
        "- Desvio padrão do intervalo: {resumo_intervalos['desvio_padrao_horas']} horas\n",
        "\n",
        "Branches:\n",
        "{branches_limpas}\n",
        "\n",
        "Merges:\n",
        "{history_limpo}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 3. Prompt estruturado\n",
        "prompt = f\"\"\"\n",
        "[INST]\n",
        "Atue como um Consultor Especialista em Governança de Software e Engenharia de Release.\n",
        "\n",
        "Analise EXCLUSIVAMENTE os dados reais extraídos do repositório GitHub do projeto \"langextract\", apresentados a seguir:\n",
        "\n",
        "{contexto_limpo}\n",
        "\n",
        " Regras obrigatórias:\n",
        "- Não assuma práticas que não estejam sustentadas por evidências técnicas observáveis.\n",
        "- Diferencie evidências diretas (branches, tags, merges, datas) de inferências analíticas.\n",
        "- Sempre descarte explicitamente os modelos que NÃO se aplicam, com justificativa técnica.\n",
        "- Utilize métricas temporais (média, mínimo, máximo e variabilidade dos intervalos) quando disponíveis.\n",
        "\n",
        "---\n",
        "\n",
        "## MODELOS DE FLUXO DE TRABALHO A CONSIDERAR\n",
        "\n",
        "Avalie e compare explicitamente os seguintes modelos:\n",
        "\n",
        "1. GitHub Flow\n",
        "   - Branch principal única (main)\n",
        "   - Branches de feature de curta duração\n",
        "   - Integração frequente via merge para a branch principal\n",
        "   - Ausência de branches permanentes de release ou develop\n",
        "\n",
        "2. Gitflow\n",
        "   - Branches permanentes: main e develop\n",
        "   - Branches específicas de release e hotfix\n",
        "   - Ciclo de integração mais longo e estruturado\n",
        "\n",
        "3. Trunk-Based Development\n",
        "   - Commits frequentes diretamente na branch principal\n",
        "   - Branches extremamente curtas ou inexistentes\n",
        "   - Forte ênfase em integração contínua\n",
        "\n",
        "---\n",
        "\n",
        "## ESTRATÉGIAS DE RELEASE A CONSIDERAR\n",
        "\n",
        "Avalie e compare explicitamente as seguintes estratégias:\n",
        "\n",
        "1. Continuous Delivery\n",
        "   - Releases frequentes e potencialmente automatizadas\n",
        "   - Baixa variabilidade temporal entre releases\n",
        "   - Relação próxima entre commits e releases\n",
        "\n",
        "2. Time-Based Release\n",
        "   - Releases em intervalos temporais relativamente regulares\n",
        "   - Baixa dispersão estatística dos intervalos\n",
        "\n",
        "3. Feature-Based Release\n",
        "   - Releases irregulares\n",
        "   - Alta variabilidade temporal\n",
        "   - Releases associadas à conclusão de funcionalidades\n",
        "\n",
        "4. Rapid Releases\n",
        "   - Releases muito frequentes (horas ou poucos dias)\n",
        "   - Baixo intervalo médio e baixo tempo entre versões consecutivas\n",
        "\n",
        "5. Release Train\n",
        "   - Releases em ciclos fixos e previsíveis\n",
        "   - Funcionalidades que não ficam prontas “embarcam no próximo trem”\n",
        "\n",
        "6. LTS + Current\n",
        "   - Existência de versões de longo suporte (LTS)\n",
        "   - Manutenção paralela de versões estáveis e versões correntes\n",
        "   - Evidência de suporte prolongado em tags ou branches\n",
        "\n",
        "---\n",
        "\n",
        "## FORMATO OBRIGATÓRIO DE RESPOSTA\n",
        "\n",
        "Estruture sua resposta EXATAMENTE da seguinte forma:\n",
        "\n",
        "# RELATÓRIO DE GOVERNANÇA: LANGEXTRACT\n",
        "\n",
        "---\n",
        "\n",
        "## 1. MODELO DE FLUXO DE TRABALHO\n",
        "Identificação: [Nome do modelo identificado]\n",
        "\n",
        "Evidências Técnicas:\n",
        "- [Liste apenas evidências observáveis do repositório]\n",
        "\n",
        "Análise Comparativa:\n",
        "- GitHub Flow: [Aderente ou não + justificativa]\n",
        "- Gitflow: [Aderente ou não + justificativa]\n",
        "- Trunk-Based Development: [Aderente ou não + justificativa]\n",
        "\n",
        "Justificativa Final:\n",
        "[Explique por que o modelo identificado é o mais adequado]\n",
        "\n",
        "---\n",
        "\n",
        "## 2. ESTRATÉGIA DE RELEASE\n",
        "Identificação: [Nome da estratégia identificada]\n",
        "\n",
        "Evidências Técnicas:\n",
        "- [Métricas temporais, padrão de tags, cadência observada]\n",
        "\n",
        "Análise Comparativa:\n",
        "- Continuous Delivery: [Aderente ou não + justificativa]\n",
        "- Time-Based Release: [Aderente ou não + justificativa]\n",
        "- Feature-Based Release: [Aderente ou não + justificativa]\n",
        "- Rapid Releases: [Aderente ou não + justificativa]\n",
        "- Release Train: [Aderente ou não + justificativa]\n",
        "- LTS + Current: [Aderente ou não + justificativa]\n",
        "\n",
        "Justificativa Final:\n",
        "[Explique por que a estratégia identificada é a mais compatível]\n",
        "\n",
        "---\n",
        "\n",
        "## 3. CONCLUSÃO SOBRE A GOVERNANÇA\n",
        "[Avaliação objetiva da maturidade da governança do projeto, destacando pontos fortes, limitações e ausência de padronização, quando aplicável]\n",
        "[/INST]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 4. Gerando a resposta\n",
        "resultado = pipe(prompt, max_new_tokens=800, temperature=0.2)\n",
        "texto_final = resultado[0]['generated_text']\n",
        "\n",
        "if \"[/INST]\" in texto_final:\n",
        "    resposta_ia = texto_final.split(\"[/INST]\")[1]\n",
        "else:\n",
        "    resposta_ia = texto_final\n",
        "\n",
        "display(Markdown(resposta_ia))"
      ],
      "metadata": {
        "id": "37m7GahHkzSz",
        "outputId": "966d94ca-0a6c-4ee4-ab4f-828ef367e2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n# RELATÓRIO DE GOVERNANÇA: LANGEXTRACT\n\n---\n\n## 1. MODELO DE FLUXO DE TRABALHO\nIdentificação: GitHub Flow\n\nEvidências Técnicas:\n- Existência de uma branch principal única (main)\n- Presença de branches de feature de curta duração\n- Frequentes integrações via merge para a branch principal\n- Ausência de branches permanentes de release ou develop\n\nAnálise Comparativa:\n- GitHub Flow: Adotado\n- Gitflow: Não adotado devido à falta de branches de release e hotfix\n- Trunk-Based Development: Não adotado devido à falta de branches curtas ou inexistentes\n\nJustificativa Final:\nO modelo GitHub Flow foi identificado como o mais adequado devido à sua flexibilidade e simplicidade, além da presença de branches de feature de curta duração que permitem uma maior velocidade de desenvolvimento e integração.\n\n---\n\n## 2. ESTRATÉGIA DE RELEASE\nIdentificação: Continuous Delivery\n\nEvidências Técnicas:\n- Frequentes releases com um intervalo médio de 277.71 horas\n- Alta coesão entre commits e releases\n- Ausência de tags de release específicas\n\nAnálise Comparativa:\n- Continuous Delivery: Adotado\n- Time-Based Release: Não adotado devido à falta de intervalos regulares entre releases\n- Feature-Based Release: Não adotado devido à alta variabilidade temporal entre releases\n- Rapid Releases: Não adotado devido à falta de intervalos extremamente curtos\n- Release Train: Não adotado devido à falta de ciclos fixos e previsíveis\n- LTS + Current: Não adotado devido à falta de tags de longo suporte\n\nJustificativa Final:\nO modelo Continuous Delivery foi identificado como o mais adequado devido à sua capacidade de permitir a entrega contínua de mudanças, com um ciclo de desenvolvimento e integração rápido e eficiente.\n\n---\n\n## 3. CONCLUSÃO SOBRE A GOVERNANÇA\n\nA governança do projeto \"langextract\" apresenta uma maturidade intermediária, com pontos fortes na adoção de modelos de fluxo de trabalho e estratégias de release e limitações na padronização dos branches e tags. A adoção do modelo GitHub Flow e do modelo Continuous Delivery foi identificada como a mais adequada para o projeto, devido à sua flexibilidade, simplicidade e capacidade de permitir uma maior velocidade de desenvolvimento e integração. No entanto, a padronização dos branches e tags pode ser melhorada para aumentar a coesão entre os desenvolvedores e a facilitação da identificação de bugs e problemas de segurança."
          },
          "metadata": {}
        }
      ]
    }
  ]
}