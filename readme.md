# An√°lise de Governan√ßa de Software com Modelos de Linguagem  
## Estudo de Caso: Projeto LangExtract

Este reposit√≥rio cont√©m os artefatos e c√≥digos desenvolvidos para a **Atividade 2 ‚Äì Ger√™ncia de Configura√ß√£o**, da disciplina **Engenharia de Software II**, com foco na an√°lise de governan√ßa em projetos open source utilizando modelos de linguagem de grande porte (LLMs).

---

## üéØ Objetivo

Analisar a governan√ßa do projeto open source **LangExtract** (Google), identificando:

- O **modelo de fluxo de trabalho** (branching model)
- A **estrat√©gia de releases**
- A **converg√™ncia de resultados** entre diferentes modelos de linguagem

A an√°lise √© baseada exclusivamente em **dados t√©cnicos reais** extra√≠dos do reposit√≥rio Git do projeto.

---
## üîó Links Importantes

- Reposit√≥rio do LangExtract:  
  https://github.com/google/langextract

- Reposit√≥rio da Atividade:  
  https://github.com/ValterSantos23/Evolucao_Software_2025-2_langextract_atividade2

- V√≠deo tutorial:  
  https://www.youtube.com/watch?v=YYo4CtIqv24
---
## üß™ Metodologia

A metodologia adotada √© composta pelas seguintes etapas:

1. **Prepara√ß√£o do Ambiente**
   - Execu√ß√£o no Google Colab
   - Instala√ß√£o das bibliotecas:
     - `transformers`
     - `bitsandbytes`
     - `accelerate`
     - `torch`

2. **Extra√ß√£o de Metadados do Reposit√≥rio**
   - Clonagem do reposit√≥rio `google/langextract`
   - Extra√ß√£o de:
     - Branches
     - Hist√≥rico de merges
     - Tags de release
     - Datas associadas √†s releases

3. **Processamento dos Dados**
   - Limpeza de c√≥digos ANSI
   - Organiza√ß√£o cronol√≥gica das releases
   - C√°lculo de m√©tricas temporais:
     - Intervalo m√©dio
     - Intervalo m√≠nimo e m√°ximo
     - Desvio padr√£o

4. **An√°lise Assistida por Modelos de Linguagem**
   - Constru√ß√£o de um **contexto t√©cnico estruturado**
   - Uso de um **prompt padronizado**
   - Execu√ß√£o independente da an√°lise com m√∫ltiplos modelos

5. **Compara√ß√£o e Discuss√£o dos Resultados**
   - Avalia√ß√£o da converg√™ncia e diverg√™ncia entre modelos
   - An√°lise da consist√™ncia das conclus√µes

---

## ü§ñ Modelos de Linguagem Utilizados

Foram utilizados **sete modelos distintos**, todos executados sob as mesmas condi√ß√µes experimentais:

| Modelo | Finalidade |
|------|-----------|
| mistralai/Mistral-7B-Instruct-v0.3 | Modelo generalista com bom equil√≠brio entre desempenho e custo |
| NousResearch/Hermes-2-Pro-Mistral-7B | √änfase em respostas longas e estruturadas |
| meta-llama/Llama-3.2-3B-Instruct | Avalia√ß√£o de modelos compactos |
| HuggingFaceH4/zephyr-7b-beta | Clareza e alinhamento instrucional |
| deepseek-ai/deepseek-coder-6.7b-instruct | Especializado em c√≥digo e engenharia de software |
| Qwen/Qwen2.5-7B-Instruct | Uso expl√≠cito de m√©tricas quantitativas |

---

## üìä Principais Resultados

### Converg√™ncia Observada
Todos os modelos identificaram:

- **Modelo de Fluxo de Trabalho:** GitHub Flow  
- **Estrat√©gia de Release:** Continuous Delivery  

### Evid√™ncias Utilizadas
- Presen√ßa de uma √∫nica branch principal (`main`)
- Uso de branches de feature de curta dura√ß√£o
- Integra√ß√£o frequente via merges
- Releases frequentes sem ciclos temporais r√≠gidos
- Aus√™ncia de vers√µes LTS ou release trains

### S√≠ntese Comparativa

| Modelo | Workflow | Estrat√©gia de Release | Observa√ß√µes |
|------|---------|----------------------|------------|
| Mistral-7B | GitHub Flow | Continuous Delivery | An√°lise equilibrada |
| Zephyr-7B | GitHub Flow | Continuous Delivery | √änfase em simplicidade |
| Llama-3.2-3B | GitHub Flow | Continuous Delivery | Coer√™ncia mesmo com menor porte |
| Qwen-2.5-7B | GitHub Flow | Continuous Delivery | Uso expl√≠cito de m√©tricas |
| Hermes-2-Pro | GitHub Flow | Continuous Delivery | An√°lise detalhada |
| DeepSeek-Coder | GitHub Flow | Continuous Delivery | Foco estrutural |
| Phi-3.5-mini | GitHub Flow | Continuous Delivery | Bom custo-benef√≠cio |

---

## üéØ Conclus√£o

Os resultados demonstram que **modelos de linguagem podem ser utilizados como ferramentas eficazes de apoio √† an√°lise de governan√ßa de software**, desde que:

- Baseados exclusivamente em dados t√©cnicos reais
- Utilizados com prompts estruturados
- Interpretados de forma cr√≠tica por analistas humanos

A forte converg√™ncia dos resultados refor√ßa a **consist√™ncia metodol√≥gica** da abordagem e indica que o projeto LangExtract apresenta um **n√≠vel adequado de maturidade de governan√ßa**, caracterizado por integra√ß√£o cont√≠nua e entregas frequentes.

---

## ‚öôÔ∏è Configura√ß√£o de Hardware Utilizada

Os experimentos foram executados no ambiente **Google Colab**, utilizando a infraestrutura padr√£o disponibilizada gratuitamente pela plataforma.

### Hardware

- **GPU:** NVIDIA Tesla T4  
- **Mem√≥ria da GPU:** 16 GB  
- **Mem√≥ria RAM:** aproximadamente 12 GB  
- **Processador:** Intel Xeon (arquitetura x86_64, virtualizado)  
- **Armazenamento:** Ambiente tempor√°rio do Google Colab  

### Justificativa da Configura√ß√£o

A GPU NVIDIA Tesla T4 foi utilizada por oferecer suporte adequado √† execu√ß√£o de modelos de linguagem de m√©dio porte (entre 3B e 7B par√¢metros), permitindo infer√™ncia eficiente em precis√£o reduzida (`float16`) sem comprometer a qualidade das respostas.

---

## üß∞ Depend√™ncias de Software

- Python 3.10+
- Bibliotecas principais:
  - `torch`
  - `transformers`
  - `accelerate`
  - `git`

---

## ‚ñ∂Ô∏è Como Executar o C√≥digo

### Passo 1 ‚Äî Abrir o ambiente

1. Acesse o **Google Colab**:  
   https://colab.research.google.com
2. Fa√ßa upload do notebook localizado em `codigo/analise_langextract.ipynb`
3. Ative a GPU:
   - Menu **Ambiente de execu√ß√£o**
   - **Alterar tipo de ambiente de execu√ß√£o**
   - Selecione **GPU**

---

### Passo 2 ‚Äî Instalar depend√™ncias

Execute a c√©lula inicial do notebook:

```bash
!pip install -q -U transformers accelerate torch

